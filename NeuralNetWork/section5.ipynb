{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import numpy as np \n",
    "import torch \n",
    "import glob \n",
    "import torchvision \n",
    "import torchvision.transforms as transforms # transform data\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim # optimzer\n",
    "import pathlib \n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import make_grid\n",
    "import math\n",
    "import random\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path= 'MINIST\\\\train\\\\'\n",
    "test_path='MINIST\\\\test\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "device='cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomRotation(object):\n",
    "\n",
    "    def __init__(self, degrees, resample=False, expand=False, center=None):\n",
    "        if isinstance(degrees, numbers.Number):\n",
    "            if degrees < 0:\n",
    "                raise ValueError(\"If degrees is a single number, it must be positive.\")\n",
    "            self.degrees = (-degrees, degrees)\n",
    "        else:\n",
    "            if len(degrees) != 2:\n",
    "                raise ValueError(\"If degrees is a sequence, it must be of len 2.\")\n",
    "            self.degrees = degrees\n",
    "\n",
    "        self.resample = resample\n",
    "        self.expand = expand\n",
    "        self.center = center\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(degrees):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        angle = np.random.uniform(degrees[0], degrees[1])\n",
    "\n",
    "        return angle\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "            img (PIL Image): Image to be rotated.\n",
    "        Returns:\n",
    "            PIL Image: Rotated image.\n",
    "        \"\"\"\n",
    "        \n",
    "        def rotate(img, angle, resample=False, expand=False, center=None):\n",
    "            \"\"\"Rotate the image by angle and then (optionally) translate it by (n_columns, n_rows)\n",
    "            Args:\n",
    "            img (PIL Image): PIL Image to be rotated.\n",
    "            angle ({float, int}): In degrees degrees counter clockwise order.\n",
    "            resample ({PIL.Image.NEAREST, PIL.Image.BILINEAR, PIL.Image.BICUBIC}, optional):\n",
    "            An optional resampling filter.\n",
    "            See http://pillow.readthedocs.io/en/3.4.x/handbook/concepts.html#filters\n",
    "            If omitted, or if the image has mode \"1\" or \"P\", it is set to PIL.Image.NEAREST.\n",
    "            expand (bool, optional): Optional expansion flag.\n",
    "            If true, expands the output image to make it large enough to hold the entire rotated image.\n",
    "            If false or omitted, make the output image the same size as the input image.\n",
    "            Note that the expand flag assumes rotation around the center and no translation.\n",
    "            center (2-tuple, optional): Optional center of rotation.\n",
    "            Origin is the upper left corner.\n",
    "            Default is the center of the image.\n",
    "            \"\"\"\n",
    "                \n",
    "            return img.rotate(angle, resample, expand, center)\n",
    "\n",
    "        angle = self.get_params(self.degrees)\n",
    "\n",
    "        return rotate(img, angle, self.resample, self.expand, self.center)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomShift(object):\n",
    "    def __init__(self, shift):\n",
    "        self.shift = shift\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_params(shift):\n",
    "        \"\"\"Get parameters for ``rotate`` for a random rotation.\n",
    "        Returns:\n",
    "            sequence: params to be passed to ``rotate`` for random rotation.\n",
    "        \"\"\"\n",
    "        hshift, vshift = np.random.uniform(-shift, shift, size=2)\n",
    "\n",
    "        return hshift, vshift \n",
    "    def __call__(self, img):\n",
    "        hshift, vshift = self.get_params(self.shift)\n",
    "        \n",
    "        return img.transform(img.size, Image.AFFINE, (1,0,hshift,0,1,vshift), resample=Image.BICUBIC, fill=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([#transforms.ToPILImage(),\n",
    "                                RandomRotation(degrees=20), RandomShift(3),\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "                            ])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([ #transforms.ToPILImage(),\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "                            ])\n",
    "    \n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path , transform=transform ) , \n",
    "    batch_size=batch_size , shuffle=True \n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path , transform=transform_test ) , \n",
    "    batch_size=batch_size , shuffle=False \n",
    ")\n",
    "# https://www.kaggle.com/code/juiyangchang/cnn-with-pytorch-0-995-accuracy/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def imshow(img):\n",
    "  ''' function to show image '''\n",
    "  # img = img / 2 + 0.5 # unnormalize\n",
    "  npimg = img.numpy() # convert to numpy objects\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "  plt.show()\n",
    "\n",
    "# for i, (images , labels ) in enumerate(train_loader):\n",
    "#         if(i < 3) :\n",
    "#           imshow(torchvision.utils.make_grid(images))        \n",
    "\n",
    "# # get random training images with iter function\n",
    "# dataiter = iter(train_loader)\n",
    "# images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/') [-1] for j in root.iterdir()])\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):    \n",
    "    def __init__(self,num_classes=5):\n",
    "        super(CNN,self).__init__()\n",
    "        #input shape : (batchsize , num of channels , height ,width )\n",
    "        #((w-f+2P)/s) +1 \n",
    "        self.conv1  = nn.Conv2d(3 , 32 , kernel_size=3, stride=1, padding=1),\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2  = nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32),\n",
    "        self.relu2 = nn.ReLU(inplace=True), \n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)#     nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "    \n",
    "        self.conv3  = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu3 = nn.ReLU(), #     nn.ReLU(inplace=True),\n",
    "\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        self.bn4 = nn.BatchNorm2d(64),\n",
    "        self.relu4 = nn.ReLU(inplace=True),\n",
    "\n",
    "        self.pool2=  nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.fc = nn.Linear(64*75*75 , out_features=num_classes)\n",
    "\n",
    "\n",
    "    def forward(self , input ) : \n",
    "        output= self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "\n",
    "        output= self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "\n",
    "        output=self.pool1(output)\n",
    "\n",
    "        output= self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "        output=self.pool2(output)\n",
    "        # out put shape with be (256,32,75,75 )\n",
    "        \n",
    "        output=output.view(-1,64*4*4)\n",
    "        output=self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# #cnn network\n",
    "\n",
    "# class CNN(nn.Module) :\n",
    "#     def __init__(self,num_classes=5):\n",
    "#         super(CNN,self).__init__()\n",
    "#         #input shape : (batchsize , num of channels , height ,width )\n",
    "#         #((w-f+2P)/s) +1 \n",
    "#         self.conv1  = nn.Conv2d(in_channels=3,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "#         #shape = (256 , 20 , 150 , 150 )\n",
    "#         self.bn1 = nn.BatchNorm2d(num_features=20)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "#         #reduce image size by a factor of 2 \n",
    "#         #shape= (256,12,75,75)\n",
    "\n",
    "#         self.conv2  = nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "#         #shape = (256 , 32, 75 , 75 )\n",
    "#         # self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         #shape = (256 , 32 , 75 , 75 )\n",
    "\n",
    "#         self.conv3  = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1)\n",
    "#         #shape = (256 , 64 , 75 , 75 )\n",
    "#         self.bn3 = nn.BatchNorm2d(num_features=64)\n",
    "#         #shape = (256 , 64 , 75 , 75 )\n",
    "#         self.relu3 = nn.ReLU()\n",
    "\n",
    "#         self.fc = nn.Linear(64*75*75 , out_features=num_classes)\n",
    "\n",
    "\n",
    "#     def forward(self , input ) : \n",
    "#         output= self.conv1(input)\n",
    "#         output=self.bn1(output)\n",
    "#         output=self.relu1(output)\n",
    "\n",
    "#         output=self.pool(output)\n",
    "\n",
    "#         output= self.conv2(output)\n",
    "#         output=self.relu2(output)\n",
    "\n",
    "#         output= self.conv3(output)\n",
    "#         output=self.bn3(output)\n",
    "#         output=self.relu3(output)\n",
    "#         # out put shape with be (256,32,75,75 )\n",
    "        \n",
    "#         output=output.view(-1,64*75*75)\n",
    "#         output=self.fc(output)\n",
    "\n",
    "#         return output\n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "optimizer =Adam(model.parameters( ) , lr=0.0001 )\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7291 2007\n"
     ]
    }
   ],
   "source": [
    "train_cnt = len(glob.glob(train_path+'/**/*.jpg') )\n",
    "test_cnt = len(glob.glob(test_path+'/**/*.jpg') )\n",
    "print(train_cnt , test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for i, (images , labels ) in enumerate(train_loader):\n",
    "        images, labels = Variable(images), Variable(labels)\n",
    "        if torch.cuda.is_available() :\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # print( images.shape)\n",
    "        exp_lr_scheduler.step()\n",
    "        outputs = model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (i + 1)% 100 == 0:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, (i + 1) * len(images), len(train_loader.dataset),\n",
    "            100. * (i + 1) / len(train_loader), loss.data[0]))\n",
    "\n",
    "\n",
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:   \n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            loss += F.cross_entropy(output, target, size_average=False).data\n",
    "\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "        \n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\git\\AIProjects2023-2024\\NeuralNetWork\\section5.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m n_epochs \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     train(epoch)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     evaluate(train_loader)\n",
      "\u001b[1;32mc:\\git\\AIProjects2023-2024\\NeuralNetWork\\section5.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# print( images.shape)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m exp_lr_scheduler\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(images)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m loss\u001b[39m=\u001b[39mloss_function(outputs,labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\git\\AIProjects2023-2024\\NeuralNetWork\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\git\\AIProjects2023-2024\\NeuralNetWork\\env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\git\\AIProjects2023-2024\\NeuralNetWork\\section5.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X16sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m , \u001b[39minput\u001b[39m ) : \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X16sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     output\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     output\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(output)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X16sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     output\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu1(output)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)\n",
    "    evaluate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediciton(data_loader):\n",
    "    model.eval()\n",
    "    test_pred = torch.LongTensor()\n",
    "    for i, data in enumerate(data_loader):\n",
    "        data = Variable(data, volatile=True)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            \n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.cpu().data.max(1, keepdim=True)[1]\n",
    "        test_pred = torch.cat((test_pred, pred), dim=0)\n",
    "        \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediciton' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\git\\AIProjects2023-2024\\NeuralNetWork\\section5.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_pred \u001b[39m=\u001b[39m prediciton(test_loader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m evaluate(test_loader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.numpy()], \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/git/AIProjects2023-2024/NeuralNetWork/section5.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#                       columns=['ImageId', 'Label'])\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prediciton' is not defined"
     ]
    }
   ],
   "source": [
    "test_pred = prediciton(test_loader)\n",
    "evaluate(test_loader)\n",
    "# out_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.numpy()], \n",
    "#                       columns=['ImageId', 'Label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
